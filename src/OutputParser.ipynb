{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tiktoken\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scenic_output(BaseModel):\n",
    "    '''\n",
    "    The output of Scenic language can be divided into the following\n",
    "    fields:\n",
    "    - Set Map and Model\n",
    "    - Constants\n",
    "        - Constants used in the following fields\n",
    "    - Monitors\n",
    "        - Traffic Light Monitors\n",
    "    - Defining Agent Behaviors\n",
    "        - Ego Behaviors\n",
    "        - Other Vehicle Behaviors (Leading Cars, Following Cars, \n",
    "        Adversary Cars, Adjacent Cars, Pedestrians, etc.)\n",
    "    - Defining Spatial Relations\n",
    "        - Geometry\n",
    "        - Placement\n",
    "    - Scenario Specifications\n",
    "        - Scenario Specifications\n",
    "    - Background Activities\n",
    "        - Defining Background Cars and Pedestrians\n",
    "    - \n",
    "    '''\n",
    "    map_and_model: str = Field(\n",
    "        ...,\n",
    "        title=\"Map and Model\",\n",
    "        description=\"The map and model of the scenario\"\n",
    "    )\n",
    "    constants: str = Field(\n",
    "        ...,\n",
    "        title=\"Constants\",\n",
    "        description=\"Constants used in the scenario\"\n",
    "    )\n",
    "    monitors: str = Field(\n",
    "        ...,\n",
    "        title=\"Monitors\",\n",
    "        description=\"Traffic Light Monitors\"\n",
    "    )\n",
    "    behaviors: str = Field(\n",
    "        ...,\n",
    "        title=\"Behaviors\",\n",
    "        description=\"Defining Agent Behaviors\"\n",
    "    )\n",
    "    spatial_relations: str = Field(\n",
    "        ...,\n",
    "        title=\"Spatial Relations\",\n",
    "        description=\"Defining Spatial Relations\"\n",
    "    )\n",
    "    scenario: str = Field(\n",
    "        ...,\n",
    "        title=\"Scenario\",\n",
    "        description=\"Scenario Specifications\"\n",
    "    )\n",
    "    background_activities: str = Field(\n",
    "        ...,\n",
    "        title=\"Background Activities\",\n",
    "        description=\"Defining Background Cars and Pedestrians\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPEN_AI_API_KEY\"] = \"sk-gDa1bvL8Ian5Rkdq186bFbDeBf904447B4C707409e660dB6\"\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "model = ChatOpenAI(\n",
    "    model_name=model_name,\n",
    "    max_tokens=2048,\n",
    "    temperature=0,\n",
    "    openai_api_key=os.environ[\"OPEN_AI_API_KEY\"],\n",
    "    openai_api_base=\"https://apikeyplus.com/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\" Scenario Description\n",
      "Traffic Scenario 01.\n",
      "Control loss without previous action.\n",
      "The ego-vehicle loses control due to bad conditions on the road and it must recover, coming back to\n",
      "its original lane.\n",
      "\"\"\"\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "with open(\"./carlaChallenge1.json\", \"r\") as f:\n",
    "    scenic_input = json.load(f) # Load the input from the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\", include_final_response_prefix=True):\n",
    "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        #print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if \"gpt-3.5\" in model:\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted                                                                                                                                                                                             \n",
    "    elif \"gpt-4\" in model:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    else:\n",
    "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md \\\n",
    "        for information on how messages are converted to tokens.\"\"\")\n",
    "    \n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    if include_final_response_prefix:\n",
    "        num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_to_chat_messages(example):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"name\": \"example_user\", \n",
    "         \"content\": '\"\"\" Scenario description\\n%s\\n\"\"\"' % example['docstring']},\n",
    "        {\"role\": \"system\", \"name\": \"example_assistant\", \n",
    "         \"content\": '```##Map and Model##\\n%s\\n##Constants##\\n%s\\n##Moniters##\\n%s\\n##Defining Agent Behaviors##\\n%s\\n##Spatial Relations##\\n%s\\n##Scenario Specifications##\\n%s\\n##Background Activities##\\n%s\\n```' \\\n",
    "             % (example['map_and_model'], example['constants'], example['monitors'], example['behaviors'], example['spatial_relations'], example['scenario'], example['background'])}\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "def get_example_num_tokens(example):\n",
    "    return num_tokens_from_messages(example_to_chat_messages(example), model_name, \n",
    "                                    include_final_response_prefix=False)\n",
    "\n",
    "def input_to_chat_messages(example):\n",
    "    docstring = example if (isinstance(example, str)) else example['docstring']\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \n",
    "         \"content\": '\"\"\" Scenario description\\n%s\\n\"\"\"' % docstring}\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "def get_input_num_tokens(example, include_final_response_prefix=True):\n",
    "    return num_tokens_from_messages(input_to_chat_messages(example), model_name, \n",
    "                                    include_final_response_prefix=include_final_response_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'name': 'example_user', 'content': '\"\"\" Scenario description\\n\"\"\" Scenario Description\\nTraffic Scenario 01.\\nControl loss without previous action.\\nThe ego-vehicle loses control due to bad conditions on the road and it must recover, coming back to\\nits original lane.\\n\"\"\"\\n\"\"\"'}, {'role': 'system', 'name': 'example_assistant', 'content': \"```##Map and Model##\\nparamparam carla_map = 'Town01'\\nmodel scenic.simulators.carla.model\\n\\n\\n##Constants##\\nEGO_MODELEGO_SPEED = 10\\n\\n\\n##Moniters##\\nNone\\n##Defining Agent Behaviors##\\nbehavior    do FollowLaneBehavior(speed)\\n\\n\\n##Spatial Relations##\\n\\nlane = Uniform(*network.lanes)\\n\\nstart = new OrientedPoint on lane.centerline\\nego = new Car at start,\\n    with blueprint EGO_MODEL,\\n    with behavior EgoBehavior(EGO_SPEED)\\n\\ndebris1 = new Debris following roadDirection for Range(10, 20)\\ndebris2 = new Debris following roadDirection from debris1 for Range(5, 10)\\ndebris3 = new Debris following roadDirection from debris2 for Range(5, 10)\\n\\nrequire (distance to intersection) > 50\\nterminate when (distance from debris3 to ego) > 10 and (distance to start) > 50\\n\\n##Scenario Specifications##\\nNone\\n##Background Activities##\\nNone\\n```\"}]\n",
      "System message tokens: 153\n"
     ]
    }
   ],
   "source": [
    "system_message_str=\"\"\"You are a helpful agent that generates specifications for car driving scenarios in the Scenic language\n",
    "Scenic is a domain-specific probabilistic programming language for modeling the environments of cyber-physical systems like robots and autonomous cars. A Scenic program defines a distribution over scenes, \\\n",
    "    configurations of physical objects and agents; sampling from this distribution yields concrete scenes which can be simulated to produce training or testing data. Scenic can also define (probabilistic) \\\n",
    "    policies for dynamic agents, allowing modeling scenarios where agents take actions over time in response to the state of the world.\n",
    "\n",
    "Your task is to generate Scenic scenarios, each according to its corresponding description in English included as a docstring. Write each scenario in a separate code box. Follow the examples below:\"\"\"\n",
    "\n",
    "system_role = \"system\" if model_name.startswith(\"gpt-4\") else \"user\"\n",
    "system_message = {\"role\": system_role, \"content\": system_message_str}\n",
    "system_message_len = num_tokens_from_messages([system_message], model_name, include_final_response_prefix=False)\n",
    "\n",
    "print(example_to_chat_messages(scenic_input))\n",
    "print(\"System message tokens: %s\" % system_message_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
